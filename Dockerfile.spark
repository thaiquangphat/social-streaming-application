FROM apache/spark:4.0.1

USER root

COPY ./requirements.txt /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements.txt


RUN wget -P /opt/spark/jars \
  https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.13/4.0.1/spark-sql-kafka-0-10_2.13-4.0.1.jar \
  && wget -P /opt/spark/jars \
  https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.13/4.0.1/spark-token-provider-kafka-0-10_2.13-4.0.1.jar \
  && wget -P /opt/spark/jars \
  https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.7.0/kafka-clients-3.7.0.jar \
  && wget -P /opt/spark/jars \
  https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar
 
ENV HF_HOME=/opt/hf_cache
ENV TRANSFORMERS_CACHE=/opt/hf_cache
RUN mkdir -p /opt/hf_cache && chmod -R 777 /opt/hf_cache

RUN mkdir -p /home/spark && chown -R 185:185 /home/spark
ENV HOME=/home/spark

WORKDIR /opt/spark-apps
ENV PYTHONPATH=/opt/spark-apps

USER spark
CMD ["bash"]
